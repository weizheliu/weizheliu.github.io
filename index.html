<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
        <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-KYQ6ZE9BDD"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-KYQ6ZE9BDD');
</script>

  <title>Weizhe Liu</title>
  
  <meta name="author" content="Weizhe Liu">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/logo.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Weizhe Liu</name>
              </p>
              <p>I am a Ph.D. candidate at <a href="https://www.epfl.ch/labs/cvlab/">CVLab</a>, <a href="https://www.epfl.ch/en/">École polytechnique fédérale de Lausanne</a> (EPFL) under the supervision of Prof. <a href="https://people.epfl.ch/pascal.fua">Pascal Fua</a>.
              </p>
              <p>
                 Prior to that, I received the Master of Science degree from <a href="https://www.epfl.ch/en/">École polytechnique fédérale de Lausanne</a> (EPFL) in 2017 and the Bachelor of Engineering degree from <a href="https://en.uestc.edu.cn/">University of Electronic Science and Technology of China</a> (UESTC) in 2014. 
              </p>
              <p style="text-align:center">
                <a href="mailto:weizhe.liu@epfl.ch">Email</a> &nbsp/&nbsp
                <a href="data/cv.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?hl=en&user=p351VxAAAAAJ">Google Scholar</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/weizhe-liu-68873589/"> LinkedIn </a>
              </p>
            </td>
            <td style="padding:5.0%;width:30%;max-width:30%">
              <a href="images/weizhe_liu.jpeg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/weizhe_liu.jpeg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research Interests</heading>
              <p>
              My research interests lie in the field of Computer Vision, Machine Learning and Robotics. My main focus is on developing algorithms to crowd analysis problem, including counting, localization and motion estimation. Recently, I also work on video understanding, action Recognition, semantic segmentation, domain adaptation and learning with less supervision.
              </p>
            </td>
          </tr>
        </tbody></table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Preprints</heading>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr onmouseout="pre4_stop()" onmouseover="pre4_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
                <div class='hidden' id='pre4'><img src='images/pre4.gif' width="180" height="160"></div>
                <div id='pre4_still'>
                    <a href='images/pre4.gif' width="180" height="160" ><img src='images/pre4_still.jpg' width="180" height="160"></a>
              </div>
                <script type="text/javascript">
                function pre4_start() {
                  document.getElementById('pre4').style.display = 'inline';
                  document.getElementById('pre4_still').style.display = 'none';
                }

                function pre4_stop() {
                  document.getElementById('pre4').style.display = 'none';
                  document.getElementById('pre4_still').style.display = 'inline';
                }
                pre4_stop()
              </script>
            </td>
                 <td style="padding:20px;width:75%;vertical-align:middle">
                   <a href="https://arxiv.org/pdf/2104.11056.pdf">
                     <papertitle>Domain Adaptation for Semantic Segmentation via Patch-Wise Contrastive Learning</papertitle>
                   </a>
                   <br>
             <strong>Weizhe Liu</strong>, David Ferstl, Samuel Schulter, Lukas Zebedin, Pascal Fua, Christian Leistner
                   <br>
                   <em>arXiv</em>
                   <br>
                   <a href="https://arxiv.org/pdf/2104.11056.pdf">pdf</a>
                   <p></p>
                   <p> We introduce a novel approach to unsupervised and semi-supervised domain adaptation for semantic segmentation. Unlike many earlier methods that rely on adversarial learning for feature alignment, we leverage contrastive learning to bridge the domain gap by aligning the features of structurally similar label patches across domains. As a result, the networks are easier to train and deliver better performance. Our approach consistently outperforms state-of-the-art unsupervised and semi-supervised methods on two challenging domain adaptive segmentation tasks, particularly with a small number of target domain annotations. It can also be naturally extended to weakly-supervised domain adaptation, where only a minor drop in accuracy can save up to 75% of annotation cost.</p>
                 </td>
               </tr>




          <tr onmouseout="pre3_stop()" onmouseover="pre3_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
                <div class='hidden' id='pre3'><img src='images/pre3.gif' width="180" height="160"></div>
                <div id='pre3_still'>
                    <a href='images/pre3.gif' width="180" height="160" ><img src='images/pre3_still.jpg' width="180" height="160"></a>
              </div>
                <script type="text/javascript">
                function pre3_start() {
                  document.getElementById('pre3').style.display = 'inline';
                  document.getElementById('pre3_still').style.display = 'none';
                }

                function pre3_stop() {
                  document.getElementById('pre3').style.display = 'none';
                  document.getElementById('pre3_still').style.display = 'inline';
                }
                pre3_stop()
              </script>
            </td>
                 <td style="padding:20px;width:75%;vertical-align:middle">
                   <a href="https://arxiv.org/pdf/2103.16291.pdf">
                     <papertitle>Leveraging Self-Supervision for Cross-Domain Crowd Counting</papertitle>
                   </a>
                   <br>
             <strong>Weizhe Liu</strong>, Nikita Durasov, Pascal Fua
                   <br>
                   <em>arXiv</em>
                   <br>
                   <a href="https://arxiv.org/pdf/2103.16291.pdf">pdf</a>
                   <p></p>
                   <p> In this paper, we train with both synthetic images, along with their associated labels, and unlabeled real images. To this end, we force our network to learn perspective-aware features by training it to recognize upside-down real images from regular ones and incorporate into it the ability to predict its own uncertainty so that it can generate useful pseudo labels for fine-tuning purposes. This yields an algorithm that consistently outperforms state-of-the-art cross-domain crowd counting ones without any extra computation at inference time.</p>
                 </td>
               </tr>

        </table>

		
		<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Published</heading>
            </td>
          </tr>
        </tbody></table>
		
		
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


          <tr onmouseout="pre2_stop()" onmouseover="pre2_start()">

            <td style="padding:20px;width:25%;vertical-align:middle">
                <div class='hidden' id='pre2'><img src='images/pre2.gif' width="180" height="160"></div>
                <div id='pre2_still'>
                    <a href='images/pre2.gif' width="180" height="160" ><img src='images/pre2_still.png' width="180" height="160"></a>
              </div>
                <script type="text/javascript">
                function pre2_start() {
                  document.getElementById('pre2').style.display = 'inline';
                  document.getElementById('pre2_still').style.display = 'none';
                }

                function pre2_stop() {
                  document.getElementById('pre2').style.display = 'none';
                  document.getElementById('pre2_still').style.display = 'inline';
                }
                pre2_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/2012.00452.pdf">
                <papertitle>Counting People by Estimating People Flows</papertitle>
              </a>
              <br>
        <strong>Weizhe Liu</strong>, Mathieu Salzmann, Pascal Fua
              <br>
              <em>IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)</em>, 2021
              <br>
              <a href="https://arxiv.org/pdf/2012.00452.pdf">pdf</a> /
              <a href="https://ieeexplore.ieee.org/document/9508171/authors#authors">press</a> /
              <a href="https://www.youtube.com/watch?v=dck3HVMLtfY">video</a> /
              <a href="https://github.com/weizheliu/People-Flows">code</a> 
              <p></p>
              <p> In this paper, we advocate estimating people flows across image locations between consecutive images and inferring the people densities from these flows instead of directly regressing them. This enables us to impose much stronger constraints encoding the conservation of the number of people. As a result, it significantly boosts performance without requiring a more complex architecture. Furthermore, it allows us to exploit the correlation between people flow and optical flow to further improve the results. We also show that leveraging people conservation constraints in both a spatial and temporal manner makes it possible to train a deep crowd counting model in an active learning setting with much fewer annotations. This significantly reduces the annotation cost while still leading to similar performance to the full supervision case. </p>
            </td>
          </tr>

		
          <tr onmouseout="eccv20_stop()" onmouseover="eccv20_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
                <div class='hidden' id='eccv20'><img src='images/eccv20.gif' width="180" height="160"></div>
                <div id='eccv20_still'>
                    <a href='images/eccv20.gif' width="180" height="160" ><img src='images/eccv20_still.png' width="180" height="160"></a>
              </div>
                <script type="text/javascript">
                function eccv20_start() {
                  document.getElementById('eccv20').style.display = 'inline';
                  document.getElementById('eccv20_still').style.display = 'none';
                }

                function eccv20_stop() {
                  document.getElementById('eccv20').style.display = 'none';
                  document.getElementById('eccv20_still').style.display = 'inline';
                }
                eccv20_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123600715.pdf">
                <papertitle>Estimating People Flows to Better Count Them in Crowded Scenes</papertitle>
              </a>
              <br>
			  <strong>Weizhe Liu</strong>, Mathieu Salzmann, Pascal Fua
              <br>
              <em>The European Conference on Computer Vision (ECCV)</em>, 2020
              <br>
              <a href="https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123600715.pdf">pdf</a> /
			  <a href="https://link.springer.com/book/10.1007/978-3-030-58452-8">press</a> /
              <a href="https://www.youtube.com/watch?v=dck3HVMLtfY">video</a> /
              <a href="https://github.com/weizheliu/People-Flows">code</a> 
              <p></p>
              <p>In this paper, we advocate estimating people flows across image locations between consecutive images and inferring the people densities from these flows instead of directly regressing. This enables us to impose much stronger constraints encoding the conservation of the number of people. As a result, it significantly boosts performance without requiring a more complex architecture. Furthermore, it also enables us to exploit the correlation between people flow and optical flow to further improve the results.</p>
            </td>
          </tr>

          <tr onmouseout="iros19_stop()" onmouseover="iros19_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
                <div class='hidden' id='iros19'><img src='images/iros19.gif' width="180" height="160"></div>
                <div id='iros19_still'>
                    <a href='images/iros19.gif' width="180" height="160" ><img src='images/iros19_still.png' width="180" height="160"></a>
              </div>
                <script type="text/javascript">
                function iros19_start() {
                  document.getElementById('iros19').style.display = 'inline';
                  document.getElementById('iros19_still').style.display = 'none';
                }

                function iros19_stop() {
                  document.getElementById('iros19').style.display = 'none';
                  document.getElementById('iros19_still').style.display = 'inline';
                }
                iros19_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/1803.08805.pdf">
                <papertitle>Geometric and Physical Constraints for Drone-Based Head Plane Crowd Density Estimation</papertitle>
              </a>
              <br>
        <strong>Weizhe Liu</strong>, Krzysztof Lis, Mathieu Salzmann, Pascal Fua
              <br>
              <em>The IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</em>, 2019
              <br>
        <a href="https://arxiv.org/pdf/1803.08805.pdf">pdf</a> /
			  <a href="https://ieeexplore.ieee.org/document/8967852">press</a> /
        <a href="https://www.youtube.com/watch?v=OLE_4Smd544">video</a>
        <p></p>
        <p>In this paper, we explicitly model the scale changes and reason in terms of people per square-meter. We show that feeding the perspective model to the network allows us to enforce global scale consistency and that this model can be obtained on the fly from the drone sensors. In addition, it also enables us to enforce physically-inspired temporal consistency constraints that do not have to be learned. This yields an algorithm that outperforms state-of-the-art methods in inferring crowd density from a moving drone camera especially when perspective effects are strong.</p>
            </td>
          </tr>		  

          <tr onmouseout="cvpr19_stop()" onmouseover="cvpr19_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
                <div class='hidden' id='cvpr19'><img src='images/cvpr19.gif' width="180" height="160"></div>
                <div id='cvpr19_still'>
                    <a href='images/cvpr19.gif' width="180" height="160" ><img src='images/cvpr19_still.png' width="180" height="160"></a>
              </div>
                <script type="text/javascript">
                function cvpr19_start() {
                  document.getElementById('cvpr19').style.display = 'inline';
                  document.getElementById('cvpr19_still').style.display = 'none';
                }

                function cvpr19_stop() {
                  document.getElementById('cvpr19').style.display = 'none';
                  document.getElementById('cvpr19_still').style.display = 'inline';
                }
                cvpr19_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Liu_Context-Aware_Crowd_Counting_CVPR_2019_paper.pdf">
                <papertitle>Context-Aware Crowd Counting</papertitle>
              </a>
              <br>
			  <strong>Weizhe Liu</strong>, Mathieu Salzmann, Pascal Fua
              <br>
              <em>The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2019
              <br>
              <a href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Liu_Context-Aware_Crowd_Counting_CVPR_2019_paper.pdf">pdf</a> /
			  <a href="https://ieeexplore.ieee.org/document/8954153">press</a> /
              <a href="https://www.youtube.com/watch?v=vEmEvs6fYyA">video</a> /
              <a href="https://github.com/weizheliu/Context-Aware-Crowd-Counting">code</a> 
              <p></p>
              <p> In this paper, we introduce an end-to-end trainable deep architecture that combines features obtained using multiple receptive field sizes and learns the importance of each such feature at each image location. In other words, our approach adaptively encodes the scale of the contextual information required to accurately predict crowd density. This yields an algorithm that outperforms state-of-the-art crowd counting methods, especially when perspective effects are strong.</p>
            </td>
          </tr>
    </table>


    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr>
      <td style="padding:20px;width:100%;vertical-align:middle">
        <heading>Professional Services</heading>
        <p>
          Reviewer of major computer vision conferences (CVPR, ICCV, ECCV) and journals (TPAMI, IJCV, TIP). </p>
      </td>
    </tr>
  </tbody></table>

    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr>
      <td style="padding:20px;width:100%;vertical-align:middle">
        <heading>Teaching</heading>
        <p>
          <ul>
            <li> <a href="https://edu.epfl.ch/coursebook/en/introduction-to-machine-learning-ba3-CS-233-A">CS-233(a), Introduction to machine learning(BA3)</a> </li>
            <li> <a href="https://edu.epfl.ch/coursebook/fr/introduction-to-machine-learning-ba4-CS-233-B">CS-233(b), Introduction to machine learning (BA4)</a> </li>
            <li> <a href="http://isa.epfl.ch/imoniteur_ISAP/!itffichecours.htm?ww_i_matiere=1775642&ww_x_anneeacad=1866895046&ww_i_section=945571&ww_i_niveau=6683117&ww_c_langue=en">MATH-233, Probabilities and statistics </a> </li>
            <li> <a href="http://isa.epfl.ch/imoniteur_ISAP/!itffichecours.htm?ww_i_matiere=1705590&ww_x_anneeacad=1866893861&ww_i_section=249847&ww_i_niveau=6683111&ww_c_langue=en">MATH-101(e), Analysis I</a> </li>

          </ul>
        </p>
      </td>
    </tr>
  </tbody></table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td>
        <br>
        <p align="right">
          <font size="1">
           <a href="https://jonbarron.info/">website template credit</a>
	    </font>
        </p>
        </td>
      </tr>
      </table>

</body>

</html>
