<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
        <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-KYQ6ZE9BDD"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-KYQ6ZE9BDD');
</script>

  <title>Weizhe Liu</title>
  
  <meta name="author" content="Weizhe Liu">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/logo.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Weizhe Liu</name>
              </p>
              <p>I am a forth-year PhD student at <a href="https://www.epfl.ch/labs/cvlab/">CVLab</a>, <a href="https://www.epfl.ch/en/">École Polytechnique Fédérale de Lausanne</a> (EPFL) under the supervision of <a href="https://people.epfl.ch/pascal.fua">Prof. Pascal Fua</a>.
              </p>
              <p>
                 Prior to that, I received the Master of Science degree from <a href="https://www.epfl.ch/en/">École Polytechnique Fédérale de Lausanne</a> (EPFL) in 2017 and the Bachelor of Engineering degree from <a href="https://en.uestc.edu.cn/">University of Electronic Science and Technology of China</a> (UESTC) in 2014. 
              </p>
              <p style="text-align:center">
                <a href="mailto:weizhe.liu@epfl.ch">Email</a> &nbsp/&nbsp
                <a href="data/cv.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?hl=en&user=p351VxAAAAAJ">Google Scholar</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/weizhe-liu-68873589/"> LinkedIn </a>
              </p>
            </td>
            <td style="padding:5.0%;width:30%;max-width:30%">
              <a href="images/weizhe_liu.jpeg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/weizhe_liu.jpeg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research Interests</heading>
              <p>
              My research interests lie in the field of Computer Vision, Machine Learning and Robotics. My main focus is on developing algorithms to solve scene understanding problems, including crowd counting and semantic segmentation. Recently, I also work on techniques such as domain adaptation and un/semi/weakly-supervised learning to reduce annotation cost.
              </p>
            </td>
          </tr>
        </tbody></table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Preprints</heading>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


          <tr onmouseout="font_stop()" onmouseover="font_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/pre2.gif' width="180" height="160">
              </div>
              <script type="text/javascript">
                function font_start() {
                  document.getElementById('font_image').style.opacity = "1";
                }

                function font_stop() {
                  document.getElementById('font_image').style.opacity = "0";
                }
                font_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/2012.00452.pdf">
                <papertitle>Counting People by Estimating People Flows</papertitle>
              </a>
              <br>
        <strong>Weizhe Liu</strong>, Mathieu Salzmann, Pascal Fua
              <br>
              <em>arXiv, extension work of our ECCV 2020 paper</em>
              <br>
              <a href="https://arxiv.org/pdf/2012.00452.pdf">pdf</a> /
              <a href="https://www.youtube.com/watch?v=dck3HVMLtfY">video</a> /
              <a href="https://github.com/weizheliu/People-Flows">code</a> 
              <p></p>
              <p> In this paper, we advocate estimating people flows across image locations between consecutive images and inferring the people densities from these flows instead of directly regressing them. This enables us to impose much stronger constraints encoding the conservation of the number of people. As a result, it significantly boosts performance without requiring a more complex architecture. Furthermore, it allows us to exploit the correlation between people flow and optical flow to further improve the results. We also show that leveraging people conservation constraints in both a spatial and temporal manner makes it possible to train a deep crowd counting model in an active learning setting with much fewer annotations. This significantly reduces the annotation cost while still leading to similar performance to the full supervision case. </p>
            </td>
          </tr>

		
          <tr onmouseout="font_stop()" onmouseover="font_start()">
                 <td style="padding:20px;width:25%;vertical-align:middle">
                   <div class="one">
                     <img src='images/pre1.gif' width="180" height="160">
                   </div>
                   <script type="text/javascript">
                     function font_start() {
                       document.getElementById('font_image').style.opacity = "1";
                     }
     
                     function font_stop() {
                       document.getElementById('font_image').style.opacity = "0";
                     }
                     font_stop()
                   </script>
                 </td>
                 <td style="padding:20px;width:75%;vertical-align:middle">
                   <a href="https://arxiv.org/pdf/1911.11484.pdf">
                     <papertitle>Using Depth for Pixel-Wise Detection of Adversarial Attacks in Crowd Counting</papertitle>
                   </a>
                   <br>
             <strong>Weizhe Liu</strong>, Mathieu Salzmann, Pascal Fua
                   <br>
                   <em>arXiv</em>
                   <br>
                   <a href="https://arxiv.org/pdf/1911.11484.pdf">pdf</a>
                   <p></p>
                   <p>In this paper, we investigate the effectiveness of existing attack strategies on crowd-counting networks, and introduce a simple yet effective pixelwise detection mechanism. It builds on the intuition that, when attacking a multitask network, in our case estimating crowd density and scene depth, both outputs will be perturbed, and thus the second one can be used for detection purposes. We will demonstrate that this significantly outperforms heuristic and uncertainty-based strategies.</p>
                 </td>
               </tr>

        </table>

		
		<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Publications</heading>
            </td>
          </tr>
        </tbody></table>
		
		
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
		
		 <tr onmouseout="font_stop()" onmouseover="font_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/eccv20.gif' width="180" height="160">
              </div>
              <script type="text/javascript">
                function font_start() {
                  document.getElementById('font_image').style.opacity = "1";
                }

                function font_stop() {
                  document.getElementById('font_image').style.opacity = "0";
                }
                font_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123600715.pdf">
                <papertitle>Estimating People Flows to Better Count Them in Crowded Scenes</papertitle>
              </a>
              <br>
			  <strong>Weizhe Liu</strong>, Mathieu Salzmann, Pascal Fua
              <br>
              <em>The European Conference on Computer Vision (ECCV)</em>, 2020
              <br>
              <a href="https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123600715.pdf">pdf</a> /
			  <a href="http://link-springer-com-443.webvpn.fjmu.edu.cn/chapter/10.1007%2F978-3-030-58555-6_43">press</a> /
              <a href="https://www.youtube.com/watch?v=dck3HVMLtfY">video</a> /
              <a href="https://github.com/weizheliu/People-Flows">code</a> 
              <p></p>
              <p>In this paper, we advocate estimating people flows across image locations between consecutive images and inferring the people densities from these flows instead of directly regressing. This enables us to impose much stronger constraints encoding the conservation of the number of people. As a result, it significantly boosts performance without requiring a more complex architecture. Furthermore, it also enables us to exploit the correlation between people flow and optical flow to further improve the results.</p>
            </td>
          </tr>

		 <tr onmouseout="font_stop()" onmouseover="font_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/iros19.gif' width="180" height="160">
              </div>
              <script type="text/javascript">
                function font_start() {
                  document.getElementById('font_image').style.opacity = "1";
                }

                function font_stop() {
                  document.getElementById('font_image').style.opacity = "0";
                }
                font_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/1803.08805.pdf">
                <papertitle>Geometric and Physical Constraints for Drone-Based Head Plane Crowd Density Estimation</papertitle>
              </a>
              <br>
        <strong>Weizhe Liu</strong>, Krzysztof Lis, Mathieu Salzmann, Pascal Fua
              <br>
              <em>The IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</em>, 2019
              <br>
        <a href="https://arxiv.org/pdf/1803.08805.pdf">pdf</a> /
			  <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8967852&tag=1">press</a> /
        <a href="https://www.youtube.com/watch?v=OLE_4Smd544">video</a>
        <p></p>
        <p>In this paper, we explicitly model the scale changes and reason in terms of people per square-meter. We show that feeding the perspective model to the network allows us to enforce global scale consistency and that this model can be obtained on the fly from the drone sensors. In addition, it also enables us to enforce physically-inspired temporal consistency constraints that do not have to be learned. This yields an algorithm that outperforms state-of-the-art methods in inferring crowd density from a moving drone camera especially when perspective effects are strong.</p>
            </td>
          </tr>		  

          <tr onmouseout="font_stop()" onmouseover="font_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/cvpr19.gif' width="180" height="160">
              </div>
              <script type="text/javascript">
                function font_start() {
                  document.getElementById('font_image').style.opacity = "1";
                }

                function font_stop() {
                  document.getElementById('font_image').style.opacity = "0";
                }
                font_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Liu_Context-Aware_Crowd_Counting_CVPR_2019_paper.pdf">
                <papertitle>Context-Aware Crowd Counting</papertitle>
              </a>
              <br>
			  <strong>Weizhe Liu</strong>, Mathieu Salzmann, Pascal Fua
              <br>
              <em>The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2019
              <br>
              <a href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Liu_Context-Aware_Crowd_Counting_CVPR_2019_paper.pdf">pdf</a> /
			  <a href="https://ieeexplore.ieee.org/document/8954153">press</a> /
              <a href="https://www.youtube.com/watch?v=vEmEvs6fYyA">video</a> /
              <a href="https://github.com/weizheliu/Context-Aware-Crowd-Counting">code</a> 
              <p></p>
              <p> In this paper, we introduce an end-to-end trainable deep architecture that combines features obtained using multiple receptive field sizes and learns the importance of each such feature at each image location. In other words, our approach adaptively encodes the scale of the contextual information required to accurately predict crowd density. This yields an algorithm that outperforms state-of-the-art crowd counting methods, especially when perspective effects are strong.</p>
            </td>
          </tr>
    </table>


    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr>
      <td style="padding:20px;width:100%;vertical-align:middle">
        <heading>Professional Services</heading>
        <p>
          Reviewer of major computer vision conferences (CVPR, ECCV etc.) and journals ( T-PAMI, IJCV, TIP etc.).        </p>
      </td>
    </tr>
  </tbody></table>

    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr>
      <td style="padding:20px;width:100%;vertical-align:middle">
        <heading>Teaching</heading>
        <p>
          <ul>
            <li> <a href="https://edu.epfl.ch/coursebook/en/introduction-to-machine-learning-ba3-CS-233-A">CS-233(a), Introduction to machine learning(BA3)</a> </li>
            <li> <a href="https://edu.epfl.ch/coursebook/fr/introduction-to-machine-learning-ba4-CS-233-B">CS-233(b), Introduction to machine learning (BA4)</a> </li>
            <li> <a href="http://isa.epfl.ch/imoniteur_ISAP/!itffichecours.htm?ww_i_matiere=1775642&ww_x_anneeacad=1866895046&ww_i_section=945571&ww_i_niveau=6683117&ww_c_langue=en">MATH-233, Probabilities and statistics </a> </li>
            <li> <a href="http://isa.epfl.ch/imoniteur_ISAP/!itffichecours.htm?ww_i_matiere=1705590&ww_x_anneeacad=1866893861&ww_i_section=249847&ww_i_niveau=6683111&ww_c_langue=en">MATH-101(e), Analysis I</a> </li>

          </ul>
        </p>
      </td>
    </tr>
  </tbody></table>

</body>

</html>
